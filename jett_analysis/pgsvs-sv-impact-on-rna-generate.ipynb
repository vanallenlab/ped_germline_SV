{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f653cbc1-3ece-4e0d-8bfd-eaff2126d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gseapy as gp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import glob\n",
    "from biomart import BiomartServer\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import gseapy as gp\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from scripts import aesthetics\n",
    "\n",
    "aesthetics.activate_paper_rcParams()\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12249b0a-d5b6-45b7-b8f1-e21c7579386a",
   "metadata": {},
   "source": [
    "# RNA SV Impact\n",
    "\n",
    "In this notebook, we'll explore the effect of SVs on expression.\n",
    "\n",
    "I'd like to try examining the impact of _ALL_ SVs on expression. This is going to take a little bit, but it should give us a sense for how some of these SVs are operating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ab3a35-0f2c-48bb-af42-bcbe30e09da0",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f0dfff5-0eca-49b2-b2bb-c0a88ceabf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define SVs and dosages for discovery and validation\n",
    "sv_path = \"gs://vanallen-pedsv-analysis/beds/PedSV.v2.5.3.full_cohort.analysis_samples.sites.bed.gz\"\n",
    "dosages_path = \"gs://vanallen-pedsv-analysis/beds/PedSV.v2.5.3.full_cohort.analysis_samples.allele_dosages.bed.gz\"\n",
    "\n",
    "# define metadata\n",
    "metadata_path = \"gs://vanallen-pedsv-analysis/sample_info/PedSV.v2.5.3.cohort_metadata.w_control_assignments.tsv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a049698-9917-4520-ad06-51ea7c39b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of genes that are annotated - drop ensembl IDs\n",
    "gene_ref = pd.read_csv(\"ref/gencode_hg38_protein_coding_genes_for_annotation_7_31_23.txt\")\n",
    "gene_ref = gene_ref[~gene_ref['value'].str.startswith('ENSG00')]\n",
    "gene_ref = gene_ref['value'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfad1ed-0377-4af7-9624-1584bee9a350",
   "metadata": {},
   "source": [
    "Load metadata and SVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "706c7c8c-50ba-4fd0-a392-2aa7133562c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\n",
    "    metadata_path,\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "\n",
    "# add a sex label to metadata\n",
    "metadata[\"sex\"] = (metadata[\"chrX_CopyNumber\"].round() < 2).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e546527-062d-425a-b7f6-d699c1bbf687",
   "metadata": {},
   "source": [
    "First, we define the samples for each analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dffe222-97cd-4b5e-a946-f35c2280d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_labels = ['gmkf_neuroblastoma', 'stjude_neuroblastoma', 'stjude_ewing']\n",
    "sample_dict = {}\n",
    "\n",
    "for l in cohort_labels:\n",
    "    cohort = 'GMKF' if 'gmkf' in l else 'StJude'\n",
    "    disease = 'neuroblastoma' if 'neuroblastoma' in l else 'ewing'\n",
    "    cohort_samples = metadata[(metadata['study'] == cohort) & (metadata['disease'] == disease)]\n",
    "    \n",
    "    # get cases and controls\n",
    "    cohort_samples = cohort_samples.query(f'{disease}_case == 1 | {disease}_control == 1')\n",
    "    \n",
    "    sample_dict[l] = cohort_samples['entity:sample_id'].tolist()\n",
    "    \n",
    "all_cohort_samples = [s for l in list(sample_dict.values()) for s in l]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712f495b-c514-451d-980f-a339306c0768",
   "metadata": {},
   "source": [
    "Now we load the counts to establish what samples are in our dataset. We have three different datasets to keep track of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51637ca9-a3d6-4162-9c24-f9c6480912ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['gmkf_neuroblastoma_normalized_counts', 'gmkf_neuroblastoma_tpms', 'gmkf_neuroblastoma_normalized_tpms',\n",
    "          'stjude_neuroblastoma_normalized_counts', 'stjude_neuroblastoma_tpms', 'stjude_neuroblastoma_normalized_tpms',\n",
    "          'stjude_ewing_normalized_counts', 'stjude_ewing_tpms', 'stjude_ewing_normalized_tpms']\n",
    "paths = [f'data/{l}.csv' for l in labels]\n",
    "\n",
    "rna_dict = {}\n",
    "for p, l in zip(paths, labels):\n",
    "    data = pd.read_csv(p, index_col = 0)\n",
    "    rna_dict[l] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08937fa-3d0f-4250-b134-366693d39b55",
   "metadata": {},
   "source": [
    "So some variation in number of genes expressed.\n",
    "\n",
    "With that said, we now need to handle our samples (ugh). First, how many samples actually overlap our cases for each disease type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "645cfe2d-bc72-4c3a-9a22-6d55b8848c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmkf_neuroblastoma_normalized_counts 89 209\n",
      "gmkf_neuroblastoma_tpms 89 209\n",
      "gmkf_neuroblastoma_normalized_tpms 89 209\n",
      "stjude_neuroblastoma_normalized_counts 60 101\n",
      "stjude_neuroblastoma_tpms 60 101\n",
      "stjude_neuroblastoma_normalized_tpms 60 101\n",
      "stjude_ewing_normalized_counts 18 24\n",
      "stjude_ewing_tpms 18 24\n",
      "stjude_ewing_normalized_tpms 18 24\n"
     ]
    }
   ],
   "source": [
    "for l, data in rna_dict.items():\n",
    "    disease = l.split('_')[1]\n",
    "    samples = set(data.columns)\n",
    "    \n",
    "    included_samples = metadata[(metadata['entity:sample_id'].isin(samples)) &\n",
    "                                (metadata[f'{disease}_case'] == True)]['entity:sample_id'].tolist()\n",
    "\n",
    "    print(l, len(included_samples), len(data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bf3c97-df16-4aa3-838a-b5901a1309d5",
   "metadata": {},
   "source": [
    "So 167 samples total, and not great recovery. For now, we drop samples that aren't in our SV dataset (we could go back later and change this, but it makes things easy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73c41280-5af8-48ba-b399-f1f84293d298",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = []\n",
    "for l, data in rna_dict.items():\n",
    "    disease = l.split('_')[1]\n",
    "    samples = set(data.columns)\n",
    "    \n",
    "    included_samples = metadata[(metadata['entity:sample_id'].isin(samples)) &\n",
    "                                (metadata[f'{disease}_case'] == True)]['entity:sample_id'].tolist()\n",
    "\n",
    "    total_samples += included_samples\n",
    "\n",
    "    rna_dict[l] = data[included_samples]\n",
    "    \n",
    "total_samples = sorted(total_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866f8de4-ff6c-4971-8a44-717508db7641",
   "metadata": {},
   "source": [
    "These are the samples that are in our dosage matrix (others were removed upstream for poor QC). Now we load the SVs. We only keep SVs and dosages that are in our count matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51a5ae5b-27b3-497f-8025-19a7f5620e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmkf_neuroblastoma_normalized_counts 89 93\n",
      "gmkf_neuroblastoma_tpms 89 93\n",
      "gmkf_neuroblastoma_normalized_tpms 89 93\n",
      "stjude_neuroblastoma_normalized_counts 60 64\n",
      "stjude_neuroblastoma_tpms 60 64\n",
      "stjude_neuroblastoma_normalized_tpms 60 64\n",
      "stjude_ewing_normalized_counts 18 22\n",
      "stjude_ewing_tpms 18 22\n",
      "stjude_ewing_normalized_tpms 18 22\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "### Dosages ###\n",
    "###############\n",
    "dosage_cols = pd.read_csv(\n",
    "    dosages_path,\n",
    "    sep=\"\\t\",\n",
    "    index_col=False,\n",
    "    nrows = 0\n",
    ")\n",
    "\n",
    "usecols = ['#chr', 'start', 'end', 'ID'] + [s for s in all_cohort_samples if s in dosage_cols.columns]\n",
    "full_dosages = pd.read_csv(\n",
    "                    dosages_path,\n",
    "                    sep=\"\\t\",\n",
    "                    index_col=False,\n",
    "                    usecols = usecols\n",
    "                )\n",
    "\n",
    "# load in the dosage data for the samples in counts\n",
    "dosage_dict = {}\n",
    "for l, data in rna_dict.items():\n",
    "    \n",
    "    # get the dosages for just this cohort\n",
    "    samples = list(data.columns)\n",
    "    cohort_dosages = full_dosages[['#chr', 'start', 'end', 'ID'] + samples]\n",
    "    dosage_dict[l] = cohort_dosages\n",
    "    cohort_dosages.to_csv(f'data/{l}-dosages-for-sv-rna-analysis.csv', index = False)\n",
    "    \n",
    "    print(l, len(data.columns), len(cohort_dosages.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6ca4d5-7056-4757-8be7-0d1b2ab3558e",
   "metadata": {},
   "source": [
    "Great, so all our samples are there. Now we do some filtering on the dosage matrix, removing SVs that are poorly genotype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac0f9a15-c3c9-4daa-a897-52f35b80c95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmkf_neuroblastoma_normalized_counts 197277 SVs dropped\n",
      "gmkf_neuroblastoma_tpms 197277 SVs dropped\n",
      "gmkf_neuroblastoma_normalized_tpms 197277 SVs dropped\n",
      "stjude_neuroblastoma_normalized_counts 196206 SVs dropped\n",
      "stjude_neuroblastoma_tpms 196206 SVs dropped\n",
      "stjude_neuroblastoma_normalized_tpms 196206 SVs dropped\n",
      "stjude_ewing_normalized_counts 208887 SVs dropped\n",
      "stjude_ewing_tpms 208887 SVs dropped\n",
      "stjude_ewing_normalized_tpms 208887 SVs dropped\n"
     ]
    }
   ],
   "source": [
    "# svs aren't filtered, so we can just keep track of all the SVs we need\n",
    "svs_to_analyze = {}\n",
    "for l, cohort_dosages in dosage_dict.items():\n",
    "\n",
    "    # identify SVs that have non-zero counts in the dosage matrix \n",
    "    temp_dosages = cohort_dosages.iloc[:, 4:].copy()\n",
    "\n",
    "    # SVs that are poorly genotyped in more than 20% of samples will be excluded\n",
    "    nan_svs = np.isnan(temp_dosages).mean(axis = 1) > 0.20\n",
    "\n",
    "    # SVs that have no counts will be excluded\n",
    "    nocount_svs = (temp_dosages.fillna(0) != 0).sum(axis = 1) == 0\n",
    "\n",
    "    kept_svs = ~(nan_svs | nocount_svs)\n",
    "    \n",
    "    cohort_dosages = cohort_dosages[kept_svs]\n",
    "\n",
    "    svs_to_analyze[l] = cohort_dosages['ID'].tolist()\n",
    "    \n",
    "    # store\n",
    "    print(l, len(temp_dosages) - len(cohort_dosages), 'SVs dropped')\n",
    "    dosage_dict[l] = cohort_dosages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70a82d58-a40a-4eca-9338-0bc092d10741",
   "metadata": {},
   "outputs": [],
   "source": [
    "svs_to_analyze_total = set()\n",
    "for sv_list in svs_to_analyze.values():\n",
    "    svs_to_analyze_total.update(sv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88bfa685-4faf-46e2-99e4-50b2d4efdaed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44136"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(svs_to_analyze_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40c60881-f88b-490e-9693-d80ce674b47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "##### SVs #####\n",
    "###############\n",
    "svs = pd.read_csv(\n",
    "    sv_path,\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "\n",
    "# subset down to all SVs in our cohort\n",
    "svs = svs[svs['name'].isin(svs_to_analyze_total)].reset_index(drop = True)\n",
    "svs.to_csv('data/svs-for-sv-rna-analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7090b047-f11f-4230-84f6-de2bcab7e936",
   "metadata": {},
   "source": [
    "With that, let's get into it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e422a96c-b911-44e6-b617-4ab032744c2c",
   "metadata": {},
   "source": [
    "# Think briefly about what information we want to carry forward\n",
    "\n",
    "We want to know how SVs affect the expression of genes around them. Most of our SVs will be singleton or very rare. We need to think about how to systematically examine gene expressions, keeping the info that we want. We have a bit of an expanding problem, in that:\n",
    "\n",
    "1. A given SV can affect multiple genes. I expect the most interesting effects to be on single gene SVs, but we should look at all of them.\n",
    "2. Multiple samples can have an SV. Common SVs can affect multiple SVs and could probably be handled by a MWU, but singleton or rare SVs cannot.\n",
    "3. SVs can have different dosages. We'll be tracking CNVs here, which can vary dramatically in terms of their dosages.\n",
    "\n",
    "It's very difficult to combine all this information into a single dataframe. In addition, we occasionally want different information. For common SVs, we can directy compare expression, but for rare and singleton SVs, a rank-based approach is likely to work better.\n",
    "\n",
    "I'm just going to make this up as I go along."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4364cc2-051b-4963-9236-1da0fd4ad0c4",
   "metadata": {},
   "source": [
    "# Identify SVs that affect genes\n",
    "\n",
    "Here, we'll identify SVs that nominally affect genes. At the end of this process, I want to end up with an SV x gene flat dataframe, where each row contains information about the SV and its relationship to the gene. This will carry forward a lot of redundant information about the SV, but that's ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0ae7102-27ad-471f-a9ef-a75e533ddeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'coding'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coding_cols = ['PREDICTED_COPY_GAIN', 'PREDICTED_INTRAGENIC_EXON_DUP', 'PREDICTED_LOF', 'PREDICTED_PARTIAL_EXON_DUP']\n",
    "noncoding_cols = ['PREDICTED_NEAREST_TSS', 'PREDICTED_INTRONIC', 'PREDICTED_PROMOTER', 'PREDICTED_UTR']\n",
    "\n",
    "# some coding columns are not included in the CWAS, but should be included here\n",
    "unimportant_coding_cols = ['PREDICTED_DUP_PARTIAL', 'PREDICTED_MSV_EXON_OVERLAP', 'PREDICTED_TSS_DUP', 'PREDICTED_INV_SPAN', 'PREDICTED_BREAKEND_EXONIC']\n",
    "\n",
    "# transform this into a lookup\n",
    "gene_rel_lookup_dict = {}\n",
    "for label, assignments in zip(['coding', 'noncoding', 'unimportant_coding'], \n",
    "                              [coding_cols, noncoding_cols, unimportant_coding_cols]):\n",
    "    for a in assignments:\n",
    "        gene_rel_lookup_dict[a] = label\n",
    "        \n",
    "gene_rel_lookup_dict['PREDICTED_COPY_GAIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a964498-db00-4074-8bca-5f579fa5521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "svs_that_affect_genes = (~pd.isnull(svs[coding_cols + noncoding_cols + unimportant_coding_cols])).sum(axis = 1) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad0a1a69-4698-4538-ad90-75e4b56e8beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44136, 1.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_svs = svs[svs_that_affect_genes]\n",
    "gene_svs.shape[0], gene_svs.shape[0] / svs.shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235d3eb0-4b1e-42f7-8fa2-37a143872e03",
   "metadata": {},
   "source": [
    "Somewhat surprisingly, all of these SVs are associated with a gene (in some fashion). But I imagine these predicted effects are extremely broad, such that all SVs get some classification here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2356842-af3d-4215-af7a-6b07336b85a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902\n",
      "334\n"
     ]
    }
   ],
   "source": [
    "coding_svs = (~pd.isnull(svs[coding_cols])).sum(axis = 1) > 0\n",
    "print(coding_svs.sum())\n",
    "\n",
    "print(((~pd.isnull(svs[unimportant_coding_cols])).sum(axis = 1) > 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d055236-d4df-4e94-8f50-c439378344d6",
   "metadata": {},
   "source": [
    "That's better. Alright, let's cobble this together. Let's define the genes that are affected by the SVs, breaking them up into their own rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95969be4-be43-44cf-9a78-eba5d6c3a981",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_gene_df = []\n",
    "\n",
    "gene_effect_df = gene_svs[['name'] + list(gene_rel_lookup_dict.keys())].set_index('name').copy()\n",
    "for sv_name, row in gene_effect_df.iterrows():\n",
    "    row = row[~pd.isnull(row)]\n",
    "    \n",
    "    for genic_rel, gene_list in row.iteritems():\n",
    "        genic_cat = gene_rel_lookup_dict[genic_rel]\n",
    "        \n",
    "        for gene in gene_list.split(','):\n",
    "            sv_gene_df.append([sv_name, genic_cat, genic_rel, gene])\n",
    "        \n",
    "sv_gene_df = pd.DataFrame(sv_gene_df, columns = ['name', 'sv_effect', 'genic_relationship', 'gene'])\n",
    "\n",
    "for sv_effect in ['coding', 'noncoding', 'unimportant_coding']:\n",
    "    counts = pd.DataFrame(sv_gene_df.query(f'sv_effect == \"{sv_effect}\"').groupby('name').size().astype(int), \n",
    "                          columns = [f'sv_{sv_effect}_counts']).reset_index()\n",
    "    sv_gene_df = sv_gene_df.merge(counts, how = 'left')\n",
    "    sv_gene_df[f'sv_{sv_effect}_counts'] = sv_gene_df[f'sv_{sv_effect}_counts'].fillna(0)\n",
    "\n",
    "# add some info about the SVs themselves\n",
    "sv_gene_df = sv_gene_df.merge(gene_svs[['#chrom', 'start', 'end', 'name', 'svtype']], on = ['name'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e41f4369-8048-4180-b731-e9ccb4e31a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sv_effect</th>\n",
       "      <th>genic_relationship</th>\n",
       "      <th>gene</th>\n",
       "      <th>sv_coding_counts</th>\n",
       "      <th>sv_noncoding_counts</th>\n",
       "      <th>sv_unimportant_coding_counts</th>\n",
       "      <th>#chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>svtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PedSV.2.5.2_CNV_chr1_1</td>\n",
       "      <td>noncoding</td>\n",
       "      <td>PREDICTED_NEAREST_TSS</td>\n",
       "      <td>OR4F5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chr1</td>\n",
       "      <td>12000</td>\n",
       "      <td>30001</td>\n",
       "      <td>CNV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PedSV.2.5.2_DUP_chr1_1</td>\n",
       "      <td>noncoding</td>\n",
       "      <td>PREDICTED_NEAREST_TSS</td>\n",
       "      <td>OR4F5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chr1</td>\n",
       "      <td>12000</td>\n",
       "      <td>40001</td>\n",
       "      <td>DUP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name  sv_effect     genic_relationship   gene  \\\n",
       "0  PedSV.2.5.2_CNV_chr1_1  noncoding  PREDICTED_NEAREST_TSS  OR4F5   \n",
       "1  PedSV.2.5.2_DUP_chr1_1  noncoding  PREDICTED_NEAREST_TSS  OR4F5   \n",
       "\n",
       "   sv_coding_counts  sv_noncoding_counts  sv_unimportant_coding_counts #chrom  \\\n",
       "0               0.0                  1.0                           0.0   chr1   \n",
       "1               0.0                  1.0                           0.0   chr1   \n",
       "\n",
       "   start    end svtype  \n",
       "0  12000  30001    CNV  \n",
       "1  12000  40001    DUP  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv_gene_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c06a48b-6e2f-4737-941d-c85b33215079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9891018669566793"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sv_gene_df.groupby(['name']).size() == 1).sum() / gene_svs.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9185c4-5766-4bdc-8b87-06fd3051cda2",
   "metadata": {},
   "source": [
    "## Remove SVs too far from their genes\n",
    "\n",
    "Some SVs are too far from their genes to reasonably have an impact on expression. We remove those here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2b6b1cf-f273-42f4-aca9-071fed3b11fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "intergenic_sv_distances = pd.read_csv('data/cwas-results/intergenic-sv-to-gene-distances.csv').rename(columns = {'gene_name': 'gene'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98e14d19-7527-4470-8eb4-898632a1569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_gene_df = sv_gene_df.merge(intergenic_sv_distances[['name', 'gene', 'distance']], on = ['name', 'gene'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecb94416-eb95-4cda-bd35-fe0ef9a05d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sv_effect</th>\n",
       "      <th>genic_relationship</th>\n",
       "      <th>gene</th>\n",
       "      <th>sv_coding_counts</th>\n",
       "      <th>sv_noncoding_counts</th>\n",
       "      <th>sv_unimportant_coding_counts</th>\n",
       "      <th>#chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>svtype</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>PedSV.2.5.2_CPX_chr1_37</td>\n",
       "      <td>noncoding</td>\n",
       "      <td>PREDICTED_NEAREST_TSS</td>\n",
       "      <td>C10orf95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chr1</td>\n",
       "      <td>13427116</td>\n",
       "      <td>13427117</td>\n",
       "      <td>CPX</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>PedSV.2.5.2_CPX_chr1_37</td>\n",
       "      <td>noncoding</td>\n",
       "      <td>PREDICTED_NEAREST_TSS</td>\n",
       "      <td>PRAMEF20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chr1</td>\n",
       "      <td>13427116</td>\n",
       "      <td>13427117</td>\n",
       "      <td>CPX</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name  sv_effect     genic_relationship      gene  \\\n",
       "357  PedSV.2.5.2_CPX_chr1_37  noncoding  PREDICTED_NEAREST_TSS  C10orf95   \n",
       "358  PedSV.2.5.2_CPX_chr1_37  noncoding  PREDICTED_NEAREST_TSS  PRAMEF20   \n",
       "\n",
       "     sv_coding_counts  sv_noncoding_counts  sv_unimportant_coding_counts  \\\n",
       "357               0.0                  2.0                           0.0   \n",
       "358               0.0                  2.0                           0.0   \n",
       "\n",
       "    #chrom     start       end svtype  distance  \n",
       "357   chr1  13427116  13427117    CPX       NaN  \n",
       "358   chr1  13427116  13427117    CPX       NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_to_drop = sv_gene_df[(sv_gene_df['genic_relationship'] == \"PREDICTED_NEAREST_TSS\") &\n",
    "                          (sv_gene_df['distance'].fillna(1e6) > 5e5)]\n",
    "rows_to_drop.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b873f1f4-b50d-4b23-b19a-7a6c65b99580",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_gene_df = sv_gene_df.drop(index = rows_to_drop.index).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446f5990-14bc-4a13-8e6d-d17e9bd5fe6c",
   "metadata": {},
   "source": [
    "## Add SV info (AF, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eec55d-2b85-47dc-97bb-10352b3409b7",
   "metadata": {},
   "source": [
    "So we can see that the majority of SVs actually only affect one gene (and this remains true for coding genes too).\n",
    "\n",
    "I'd like to add some info about AF in our cohort subset here. Calculating these are _EXTREMELY_ annoying, since we have mixed CNVs and short SVs. We have to do this for each cohort, since the number of samples in each is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "709041ff-1e72-4b37-b332-461d51977e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmkf_neuroblastoma_normalized_counts\n",
      "gmkf_neuroblastoma_tpms\n",
      "gmkf_neuroblastoma_normalized_tpms\n",
      "stjude_neuroblastoma_normalized_counts\n",
      "stjude_neuroblastoma_tpms\n",
      "stjude_neuroblastoma_normalized_tpms\n",
      "stjude_ewing_normalized_counts\n",
      "stjude_ewing_tpms\n",
      "stjude_ewing_normalized_tpms\n"
     ]
    }
   ],
   "source": [
    "cohort_sv_gene_dict = {}\n",
    "\n",
    "for l in rna_dict.keys():\n",
    "    print(l)\n",
    "    \n",
    "    cohort = '_'.join(l.split('_')[:2])\n",
    "    \n",
    "    # get all the cohort samples (cases and controls) to calculate the AF\n",
    "    cohort_samples = sample_dict[cohort]\n",
    "    cohort_dosages = full_dosages[['ID'] + cohort_samples].set_index('ID')\n",
    "    \n",
    "    # to calculate how many of our RNA eligible samples are affected, we need the dosages of just those.\n",
    "    # we also only analyze these.\n",
    "    cohort_rna_dosages = dosage_dict[l].iloc[:, 3:].set_index('ID')\n",
    "    \n",
    "    cohort_svs_to_analyze = list(cohort_rna_dosages.index)\n",
    "    \n",
    "    # subset to just these SVs\n",
    "    cohort_dosages = cohort_dosages.loc[cohort_svs_to_analyze]\n",
    "    \n",
    "    sv_allele_fractions = []\n",
    "    \n",
    "    for sv_name in cohort_svs_to_analyze:\n",
    "\n",
    "        sv_full_dosages = cohort_dosages.loc[sv_name].dropna()\n",
    "        sv_rna_dosages = cohort_rna_dosages.loc[sv_name].dropna()\n",
    "\n",
    "        if '_CNV' in sv_name:\n",
    "            average_cn = np.mean(sv_full_dosages)\n",
    "            af = np.nan\n",
    "\n",
    "        else:\n",
    "            allele_counts = sv_full_dosages.value_counts().reindex([0, 1, 2]).fillna(0)\n",
    "            alt = (allele_counts * np.array([0, 1, 2])).sum()\n",
    "            ref = len(sv_full_dosages) * 2\n",
    "\n",
    "            af = alt/ref\n",
    "            average_cn = np.nan\n",
    "            \n",
    "        # calculate the number of affected samples with RNA\n",
    "        num_rna_samples_affected = (sv_rna_dosages > 0).sum()\n",
    "\n",
    "        sv_allele_fractions.append([l, sv_name, num_rna_samples_affected, af, average_cn])\n",
    "\n",
    "    sv_allele_fractions = pd.DataFrame(sv_allele_fractions, columns = ['cohort', 'name', 'num_samples_with_rna_affected', 'cohort_af', 'average_cn'])\n",
    "    \n",
    "    # get the cohort SVs\n",
    "    cohort_sv_gene_df = sv_gene_df[sv_gene_df['name'].isin(cohort_svs_to_analyze)].copy()\n",
    "    cohort_sv_gene_df = cohort_sv_gene_df.merge(sv_allele_fractions, on = 'name', how = 'left')\n",
    "\n",
    "    cohort_sv_gene_dict[l] = cohort_sv_gene_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f85384-d07b-43ce-997e-d828600cc954",
   "metadata": {},
   "source": [
    "# Time to look at the RNA\n",
    "\n",
    "I want to do this fully systematically, and then afterwards we can go back and reassess. We have a few different issues that we need to handle:\n",
    "\n",
    "1. Different numbers of samples affected. Some SVs affect many samples, and some affect very few.\n",
    "2. SV dosages. While rare SVs will usually only have `0` or `1` as dosages, others will have `1/2`. \n",
    "3. `CNV`s have way crazier dosages. They should be modelled more holistically.\n",
    "4. Modelling TPMs/counts as an outcome is really annoying (requiring something like DESeq optimally), and non-parametric approaches like the MWU cannot handle multiple covariates.\n",
    "\n",
    "This is a ton to keep track of, as we want to handle these scenarios differently. Here's what we'll do. For each `SV` and `gene` pair, we'll generate the following:\n",
    "\n",
    "1. The average rank of affected samples (non-zero allele). This will be incorrect for CNVs that can have a range of copy numbers that includes negative ones.\n",
    "    * We also include the expression of affected vs. not samples\n",
    "2. MWU test between affected (non-zero allele) and not. This will be incorrect for SVs that have few samples and for SVs that have more dosages.\n",
    "3. An ordinal logistic regression model, incorporating dosage and using the ranks of gene expression as the outcome. This will be broadly incorrect because it does not appropriately model counts.\n",
    "4. The average expression of the gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3760d42-a889-45e6-8888-675ce21f7744",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.miscmodels.ordinal_model import OrderedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb68319d-aae3-4bf4-8b1c-a27422fa3d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31610"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(svs_to_analyze['gmkf_neuroblastoma_tpms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6b9856-202a-4987-b9eb-50925a8edd87",
   "metadata": {},
   "source": [
    "I hate this nested code structure, but anything else is too complicated. We do this for every cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6f8efa9-91cd-4181-a475-37e69e8f2b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmkf_neuroblastoma_normalized_counts\n",
      "0, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, 10000, 10500, 11000, 11500, 12000, 12500, 13000, 13500, 14000, 14500, 15000, 15500, 16000, 16500, 17000, 17500, 18000, 18500, 19000, 19500, 20000, 20500, 21000, 21500, 22000, 22500, 23000, gmkf_neuroblastoma_tpms\n",
      "0, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, 10000, 10500, 11000, 11500, 12000, 12500, 13000, 13500, 14000, 14500, 15000, 15500, 16000, 16500, 17000, 17500, 18000, 18500, 19000, 19500, 20000, 20500, 21000, 21500, 22000, 22500, 23000, gmkf_neuroblastoma_normalized_tpms\n",
      "0, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, 10000, 10500, 11000, 11500, 12000, 12500, 13000, 13500, 14000, 14500, 15000, 15500, 16000, 16500, 17000, 17500, 18000, 18500, 19000, 19500, 20000, 20500, 21000, 21500, 22000, 22500, 23000, stjude_neuroblastoma_normalized_counts\n",
      "0, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, 10000, 10500, 11000, 11500, 12000, 12500, 13000, 13500, 14000, 14500, 15000, 15500, 16000, 16500, 17000, 17500, 18000, 18500, 19000, 19500, 20000, 20500, 21000, 21500, 22000, 22500, 23000, 23500, 24000, 24500, 25000, stjude_neuroblastoma_tpms\n",
      "0, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, 10000, 10500, 11000, 11500, 12000, 12500, 13000, 13500, 14000, 14500, 15000, 15500, 16000, 16500, 17000, 17500, 18000, 18500, 19000, 19500, 20000, 20500, 21000, 21500, 22000, 22500, 23000, 23500, 24000, 24500, 25000, stjude_neuroblastoma_normalized_tpms\n",
      "0, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, 10000, 10500, 11000, 11500, 12000, 12500, 13000, 13500, 14000, 14500, 15000, 15500, 16000, 16500, 17000, 17500, 18000, 18500, 19000, 19500, 20000, 20500, 21000, 21500, 22000, 22500, 23000, 23500, 24000, 24500, 25000, stjude_ewing_normalized_counts\n",
      "0, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, 10000, 10500, 11000, 11500, 12000, 12500, 13000, 13500, 14000, 14500, stjude_ewing_tpms\n",
      "0, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, 10000, 10500, 11000, 11500, 12000, 12500, 13000, 13500, 14000, 14500, stjude_ewing_normalized_tpms\n",
      "0, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, 10000, 10500, 11000, 11500, 12000, 12500, 13000, 13500, 14000, 14500, "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for l, data in rna_dict.items():\n",
    "    print(l)\n",
    "    \n",
    "    analysis_dosages = dosage_dict[l].iloc[:, 3:].set_index('ID')\n",
    "    svs_to_analyze_cohort = svs_to_analyze[l]\n",
    "    \n",
    "    sv_gene_df_cohort = cohort_sv_gene_dict[l]\n",
    "    \n",
    "    # drop genes not present in our counts\n",
    "    sv_gene_df_cohort = sv_gene_df_cohort[sv_gene_df_cohort['gene'].isin(data.index)]\n",
    "    \n",
    "    cohort_results = []\n",
    "\n",
    "    base_row = [l]\n",
    "    \n",
    "    for i, (index, row) in enumerate(sv_gene_df_cohort.iterrows()):\n",
    "        if i % 500 == 0:\n",
    "            print(i, end = ', ')\n",
    "\n",
    "        gene = row['gene']\n",
    "        sv = row['name']\n",
    "        gr = row['genic_relationship']\n",
    "\n",
    "        storage_row = base_row + [sv, gene, gr]\n",
    "\n",
    "        # get the dosages\n",
    "        sv_dosages = analysis_dosages.loc[sv].dropna()\n",
    "\n",
    "        # get the expression\n",
    "        gene_expression = data.loc[gene, sv_dosages.index]\n",
    "        mean_expression = gene_expression.mean()\n",
    "\n",
    "        storage_row.append(mean_expression)\n",
    "\n",
    "        ###########################\n",
    "        ### RANK-BASED APPROACH ###\n",
    "        ###########################\n",
    "        affected_samples = sv_dosages[sv_dosages > 0].index\n",
    "        unaffected_samples = sv_dosages[sv_dosages <= 0].index\n",
    "\n",
    "        # rank the expression\n",
    "        expression_ranks = (gene_expression.rank(ascending = False) - 1)\n",
    "        norm_expression_ranks =  expression_ranks / (len(gene_expression) - 1)\n",
    "\n",
    "        avg_affected_rank = norm_expression_ranks.loc[affected_samples].mean()\n",
    "\n",
    "        # store this data\n",
    "        storage_row += [len(sv_dosages), len(affected_samples), avg_affected_rank]\n",
    "        \n",
    "        # store the expression of affected and unaffected\n",
    "        gene_exp_affected = gene_expression.loc[affected_samples]\n",
    "        gene_exp_unaffected = gene_expression.loc[unaffected_samples]\n",
    "        storage_row += [gene_exp_affected.mean(), gene_exp_unaffected.mean()]\n",
    "        \n",
    "        ##################\n",
    "        ### EXIT CHECK ###\n",
    "        ##################\n",
    "        \n",
    "        # If there are fewer than 3 affected samples, a MWU or ordinal regression\n",
    "        # doesn't make sense. We exit then.\n",
    "        if len(affected_samples) == 1:\n",
    "            storage_row += [np.nan]\n",
    "            cohort_results.append(storage_row)\n",
    "            continue\n",
    "\n",
    "        ################\n",
    "        ### MWU TEST ###\n",
    "        ################ \n",
    "        try:\n",
    "            p = stats.mannwhitneyu(gene_exp_affected, gene_exp_unaffected)[1]\n",
    "        except:\n",
    "            p = np.nan\n",
    "\n",
    "        storage_row += [p]\n",
    "\n",
    "        ###################################\n",
    "        ### LOGISTIC ORDINAL REGRESSION ###\n",
    "        ###################################\n",
    "    \n",
    "#         data = pd.DataFrame([expression_ranks, sv_dosages], index = ['rank', 'dose']).T\n",
    "\n",
    "#         # have to convert rank to an ordered variable\n",
    "#         data['rank'] = pd.Categorical(data['rank'], categories=sorted(set(data['rank']))[::-1], ordered=True)\n",
    "\n",
    "#         try:\n",
    "#             mod_log = OrderedModel(data['rank'],\n",
    "#                            data[['dose']],\n",
    "#                            distr='logit')\n",
    "\n",
    "#             res_log = mod_log.fit(method='bfgs', disp=False)\n",
    "\n",
    "#             p = res_log.pvalues.loc['dose']\n",
    "#             coef = res_log.params.loc['dose']\n",
    "\n",
    "#         except:\n",
    "#             p, coef = np.nan, np.nan\n",
    "\n",
    "#         storage_row += [p, coef]\n",
    "\n",
    "        cohort_results.append(storage_row)\n",
    "        \n",
    "    columns = ['cohort', 'name', 'gene', 'genic_relationship', 'mean_exp', 'num_rna_genotyped', 'num_greater_0_dosage', 'mean_greater_0_dosage_rank', 'mean_greater_0_exp', 'mean_leq_0_exp', \n",
    "               'mwu_p']\n",
    "    \n",
    "    cohort_results = pd.DataFrame(cohort_results, columns = columns)\n",
    "    \n",
    "    # merge with the cohort's sv information\n",
    "    sv_gene_df_cohort = sv_gene_df_cohort.merge(cohort_results, on = ['name', 'gene', 'genic_relationship', 'cohort'], how = 'left').drop(columns = 'num_samples_with_rna_affected')\n",
    "    \n",
    "    results.append(sv_gene_df_cohort)\n",
    "\n",
    "results = pd.concat(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6794b9-8232-4465-9c22-06b1875cf6b7",
   "metadata": {},
   "source": [
    "Finally, I do want to swap the rank around, such that `0 = low | 1 = high`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e60f6364-5c5b-4a80-a34e-1b6daa529d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['mean_greater_0_dosage_rank'] = 1 - results['mean_greater_0_dosage_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f07eebe0-758d-404c-b489-b5ae461e8463",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('data/sv-expression-results/sv-gene-rna-results-all-cohorts-all-analyses.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pediatric-germline-svs-3.7.13",
   "language": "python",
   "name": "pediatric-germline-svs-3.7.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
